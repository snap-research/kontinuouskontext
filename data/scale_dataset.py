import torch 
import numpy as np
import torch.nn as nn 
import json 
from torch.utils.data import Dataset
from PIL import Image
import os 
import random 
import lpips
from torchvision import transforms 

# This is the custom dataloader for the sliders datasset, it will load the input and edited image, prompt and the slider values for the edits. 
class SliderDataset(Dataset):
    def __init__(
        self,
        data_json_path, # path where the .json file will be present, that have the filenames and the edits 
        image_dataset_path, # path for the image dataset, that will have the stack of images with original and the interpolated images that need to be processed to obtain pairs 
        image_size: int = 512, # size of the input image on which we will be training 
        drop_text_prob: float = 0.1, # the text conditioning will be dropped with this probability 
        drop_slider_prob: float = 0.1, # the slider conditionining will be dropped with this probability 
        filter: str = "no-filter",
        return_pil_image: bool = False, # 0.15 # the threshold for the kl divergence between the sample lpips sequence and the uniform distribution 
    ):

        # Loading the paths for all the required components of the dataset 
        self.imgs_dir = image_dataset_path # this folder will have stack of images generated by the interpolation models and filtereed based on some criteria 
        # this metadata will have .json and the information for all the images stacked in the single .json file 
        self.meta_data_path = data_json_path
        # Loading the meta data directly from the .json that will be used for processing in the dataloader 
        self.meta_data = json.load(open(self.meta_data_path)) # loading the meta data from the json file 

        # ------------ for overfitting case, defining the meta-data with a single image ------------ # 
        # self.meta_data = self.meta_data[122:123] # working with a single example 
        print("--------- meta data loaded with n_images: {} ----------".format(len(self.meta_data)))

        print("sample meta data: {}".format(self.meta_data[0])) 

        self.img_size = image_size
        self.drop_text_prob = drop_text_prob
        self.drop_slider_prob = drop_slider_prob
        self.return_pil_image = return_pil_image

        # defining the lpips function for computation of distance between samples. 
        loss_fn_vgg = lpips.LPIPS(net='vgg')
        self.loss_fn_vgg = loss_fn_vgg 
        self.loss_fn_vgg.eval()

        print("----- Using drop text with prob: {} -----".format(self.drop_text_prob))

        self.image_transforms = transforms.Compose(
                [
                    transforms.ToTensor(),
                    transforms.Normalize([0.5], [0.5]),
                ]
            )
        self.to_tensor = transforms.ToTensor()
        self.custom_instance_prompts = ["temp just to run the code"]

    def __len__(self):
        return len(self.meta_data) 

    # This function will disintegrate the image into a list of images, the stack has images horizontally stacked with each other and we want to crop the images 
    def disintegrate_image_stack(self, image_stack):
        width, height = image_stack.size
        n_imgs = width // height
        img_width = width // n_imgs
        img_height = height 

        list_stacked_images = []
        # Iterating over the number of images for the edits and saving cropped images in the list 
        for i in range(n_imgs):
            list_stacked_images.append(image_stack.crop((img_width * i, 0, img_width * (i + 1), img_height)))
        
        return list_stacked_images 

    # This function will sample a random image from the interpolation and will return the source image and the interpolated image along with its index, 
    # The index will range from 1 to n_edits - 1, as [1-6] in our case  
    def sample_from_list(self, image_list, n_edits):
        # Ignore any global seed for this block to ensure true randomness
        state = random.getstate()
        random.seed(np.random.randint(0, 1000000)) 
        sampled_idx = random.randint(0, n_edits-1) # it includes both the end points during sampling, this will sample all the way from 0 to 6, in total 7 edits, we are sampling the zeroth edit as well for regularization of training. 
        random.setstate(state)

        # print("sampled_idx: {}".format(sampled_idx))    

        src_img = image_list[0] # taking the 
        edit_img = image_list[sampled_idx] # can also have the zeroth edit as we are including that into training 
        # getting the slider value as the fraction value between [1/6 to 1.0] that will be used for training 
        slider_value = sampled_idx / (n_edits - 1) # dividing by 6, so the edits are in a range of (0,1] 
        return src_img, edit_img, slider_value 
    
    # This function will extract a random image from the stack and the corresponding slider value will be used to generate the edit and the output 
    def sample_edit_pair(self, image_stack, n_edits): 
        list_stacked_images = self.disintegrate_image_stack(image_stack)
        # print("list_stacked_images: {}".format(len(list_stacked_images)))  

        # for testing purposes, saving the intermediate images and analyzing is the data being accessed correctly 
        # for idx in range(len(list_stacked_images)):
        #     list_stacked_images[idx].save(f"./debug/image_{idx}.png") 

        # the first and the last images are the real images and the intermediate ones as the interpolated images 
        list_interpolated_images = list_stacked_images

        # this function will sample a random image and a scalar value according to it between [1/(n_edits-1) to 1.0] as the extent of the edits   
        src_img, edit_img, slider_value = self.sample_from_list(list_interpolated_images, n_edits)  

        # returning the extracted edit image and the edit strength that is normalized between [0.0 to 1.0] 
        return src_img, edit_img, slider_value, list_stacked_images 

    # this function will compute the cdf of the lpips sequence and then returns the mapping to the normalized slider values based on the cdf 
    def get_normalized_sliders(self, lpips_sequence):
        # removing the first and the last images as they are the real images and we are not interested in them 
        lpips_sequence_intermediate = lpips_sequence[1:-1]
        # computing the cummulative sum till that point in the sequence to get the cummulative distribution 
        cumm_lpips = [0] # adding a zero as the first element and the next ones will be subsequent 
        for i in range(len(lpips_sequence_intermediate)):
            cumm_lpips.append(np.sum(lpips_sequence_intermediate[:i+1]))
        # this should be of size 6 + 1 = 7, six edits and one for the source image 

        # normalizing the cummulative sum to get the fraction of change for each of the step in the sequence 
        for i in range(len(cumm_lpips)):
            cumm_lpips[i] = cumm_lpips[i] / cumm_lpips[-1] 

        return cumm_lpips

    # this function will map the fixed slider value to the normalized one based on the cdf of the sequence 
    def get_mapped_slider(self, sliders_cdf, slider_value):
        # here slider values will range from [0, 1/6 .... 6/6] | 7 values in total 
        slider_value_index = int(slider_value * 6)# now the range is from 0-6 
        # print("slider value index: {}".format(slider_value_index))
        slider_value_mapped = sliders_cdf[slider_value_index]  # mapping the sliders 
        return slider_value_mapped

    # Loading a single data point from the dataset 
    def __getitem__(self, idx):
        # Loading the image 
        try:
            # print("requested index: {}".format(idx)) 
            image_meta_data_sample = self.meta_data[idx] # Extracting one row from the meta data, we will use that to get the image name and the edit instruction used for training 
            # print("image_meta_data_sample: {}".format(image_meta_data_sample)) 
            
            # Extacting the image name and the edit instruction from the meta data to perform the processing 
            image_name = image_meta_data_sample['image_name'] # getting the image name 
            edit_instruction = image_meta_data_sample['edit_prompt'] # for v2 the json is in this structure 
            edit_category = image_meta_data_sample['category'] # getting the edit category from one of the original data categories 

            # currently we are interpolating from the dataset that have 7 images stacked togather and there is a starting and the ending image that are the real images in the dataset 
            n_edits = 7 
            image_stack_path = os.path.join(self.imgs_dir, image_name) 
            # print("image_stack_path: {}".format(image_stack_path)) 
            img_stack = Image.open(image_stack_path) 
            # print("image loaded: {}".format(img_stack.size)) 
                        
            # This function will extract the image pairs and the scalar strength values to be used for training the model 
            # returning the stack of images also for computationg of the lpips scores 
            img_src, img_edit, slider_value, list_images_stack = self.sample_edit_pair(img_stack, n_edits)  

            # resizing the image to the required size for the source and the edited image for training 
            img_src = img_src.resize((self.img_size, self.img_size)).convert("RGB")
            img_edit = img_edit.resize((self.img_size, self.img_size)).convert("RGB")

            # Randomly drop text or image
            drop_text = random.random() < self.drop_text_prob
            drop_slider = random.random() < self.drop_slider_prob
            
            if drop_text:
                edit_instruction = ""
            if drop_slider:
                slider_value = 0.5 

            # print("returned src image shape: {}".format(self.image_transforms(img_src).shape)) 
            # print("returned edit image shape: {}".format(self.image_transforms(img_edit).shape))  

            return {
                "src_image": self.image_transforms(img_src),
                "edit_image": self.image_transforms(img_edit),
                "instruction": edit_instruction,
                "slider_value": slider_value, 
            }

        except Exception as e:
            # print("Error in the data point: {}".format(e))
            # print("moving to the next sample ... ")
            # This will be called if the data point is not valid then, we will access a randomg point from the dataset. 
            return self.__getitem__(np.random.randint(0, self.__len__())) 

# --------------------------------------------------------------------- # 